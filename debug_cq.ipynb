{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38feaf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from training_with_sentence_transformers.models import ColBERTTransformer\n",
    "import gzip\n",
    "\n",
    "\n",
    "#MODEL_DIR=colbert_splade_distill_num1_updatemrr2000_kldiv_ib_position_focal_gamma5.0-alpha1.0-ibp0.1_denoiseFalse_num20_kldiv_ib_position_focal5-lr1e-05-batch_size_16x2-2023-01-20\n",
    "#python inference_ColBERT.py training_with_sentence_transformers/output/$MODEL_DIR/42000/0_ColBERTTransformer training_with_sentence_transformers/output/$MODEL_DIR/index_42k\n",
    "\n",
    "agg = \"max\"\n",
    "bsize = 128\n",
    "model_type_or_dir = \"training_with_sentence_transformers/output/colbert_cont_128_num20_kldiv_ib5-lr1e-05-batch_size_32x1-2023-04-17/236000/0_ColBERTTransformer\" #\"colspla-prf_from_colbert_3e-6_negpersys5\" #\"output/0_MLMTransformer\"\n",
    "\n",
    "# loading model and tokenizer\n",
    "dense_weight = 0.0\n",
    "model = ColBERTTransformer(model_type_or_dir, max_seq_length=256, dim=128)\n",
    "checkpoint = torch.load(os.path.join(model_type_or_dir, \"checkpoint.pt\"), map_location='cpu')\n",
    "model.load_state_dict(checkpoint)\n",
    "    \n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type_or_dir)\n",
    "tokens = [\"[unused0]\", \"[unused1]\", \"[unused2]\"] #[unused0] for query, [unused1] for doc, [unused2] for query expansion\n",
    "tokenizer.add_tokens(tokens, special_tokens=True)\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c6051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../msmarco/collection.tsv\") as f:\n",
    "    for line in tqdm(f):\n",
    "        did, doc = line.strip().split(\"\\t\")    \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e794de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    d_features = tokenizer(\"[unused1] \" + doc, return_tensors=\"pt\", truncation=True).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592f2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    doc_rep = model(d_features)\n",
    "d_mask = doc_rep['attention_mask'].to('cuda')\n",
    "d_mask = d_mask.unsqueeze(-1)\n",
    "d_emb = doc_rep['last_layer_embeddings']\n",
    "token_rep_d =  d_emb * d_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a70d2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 56, 128])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_rep_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f5ec5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,     2,  1996,  3739,  1997,  4807, 13463,  4045,  9273,  2001,\n",
       "          8053,  2590,  2000,  1996,  3112,  1997,  1996,  7128,  2622,  2004,\n",
       "          4045, 24823,  2001,  1012,  1996,  2069,  6112,  5689,  2058,  1996,\n",
       "          8052,  6344,  1997,  1996,  9593,  6950,  1998,  6145,  2003,  2054,\n",
       "          2037,  3112,  5621,  3214,  1025,  5606,  1997,  5190,  1997,  7036,\n",
       "          3268, 27885, 22779,  9250,  1012,   102]], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_features['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9244f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## another way when we deal with static embedding\n",
    "\n",
    "non_context = [model({'input_ids':torch.tensor([[101, 2, tok, 102]]).to('cuda'), 'token_type_ids':  torch.tensor([[0,0,0,0]]).to('cuda'), \n",
    "       'attention_mask': torch.tensor([[1,1,1,1]]).to('cuda')})['last_layer_embeddings'][:,2,:] for tok in d_features['input_ids'].tolist()[0]]\n",
    "\n",
    "non_context = torch.stack(non_context,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "20eb20ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.1446, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.9286, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.2465, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.6897, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.3179, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7382, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.5947, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7179, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.6965, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.3768, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.8051, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7754, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.3616, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.2756, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7610, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.2471, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.3046, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7783, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7732, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.4955, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7367, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7401, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.4148, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.2260, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.2206, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.6204, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.6673, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.6254, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.5706, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.2977, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.6855, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.6545, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.3041, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.3008, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7525, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.6276, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.2548, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.6467, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.4076, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.1503, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.3793, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7816, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7329, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.7330, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.3601, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.4928, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.2595, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.4060, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.2248, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.5851, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.5448, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.5510, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.3581, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.4394, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.3302, device='cuda:0', grad_fn=<DotBackward0>),\n",
       " tensor(0.4464, device='cuda:0', grad_fn=<DotBackward0>)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.dot(torch.nn.functional.normalize(non_context[0])[i], torch.nn.functional.normalize(token_rep_d[0])[i]) for i in range(non_context.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1dd950ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0174, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.dot(torch.tensor(doc_emb[0,i]), torch.tensor(non_context[i])) for i in range(len(doc_emb))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f8f344fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3179, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.nn.functional.normalize(non_context[:,2,:]) * torch.nn.functional.normalize(token_rep_d[:,4,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c23e3bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_norm = torch.nn.functional.normalize(token_rep_d, dim = 2)\n",
    "static_norm = torch.nn.functional.normalize(non_context[:,1:2,:], dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d1ad7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1150, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(doc_norm[0,1,:] * static_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82f703d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(doc_norm, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3bfaf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.3690e-02,  5.6263e-02,  1.6762e-03, -7.0259e-02,  6.0122e-05,\n",
       "           1.0090e-02, -9.4712e-02, -1.2329e-01,  7.4517e-02, -2.5461e-02,\n",
       "           2.4914e-02,  1.7607e-02,  1.1017e-01,  1.3662e-02,  2.3778e-02,\n",
       "           1.2803e-01, -2.0093e-01,  4.1182e-02, -9.9289e-02,  2.4423e-02,\n",
       "           1.6703e-01, -2.1474e-03,  4.7846e-02,  5.0802e-02,  8.6490e-02,\n",
       "           3.4477e-02,  3.1344e-02,  1.0562e-01, -1.3178e-01,  4.9349e-02,\n",
       "          -1.5922e-02, -2.5611e-02, -2.2045e-02,  1.1995e-01, -4.0245e-02,\n",
       "           1.2449e-01, -1.1227e-01,  8.9956e-02,  1.1854e-02,  1.3891e-01,\n",
       "          -6.7069e-02, -1.0372e-01, -3.1512e-02, -5.2647e-02,  9.2421e-02,\n",
       "          -1.2634e-02,  1.0818e-02,  7.6936e-02,  4.0735e-02, -5.1563e-02,\n",
       "          -2.4714e-02, -2.9732e-02, -7.4961e-02, -2.0589e-03, -1.5524e-01,\n",
       "           7.7767e-02, -1.4685e-02,  7.5426e-03, -1.1453e-02,  6.6873e-02,\n",
       "          -9.3952e-02, -7.2675e-02, -6.1948e-02, -3.4644e-02, -7.5766e-02,\n",
       "           2.5492e-02,  8.8960e-02,  7.9024e-02, -7.2996e-03,  8.3921e-03,\n",
       "           2.1018e-02, -3.7772e-02, -7.0349e-02,  3.4758e-02, -5.8152e-01,\n",
       "          -7.2953e-02, -2.3479e-02,  5.1086e-02,  1.0515e-02,  5.9351e-03,\n",
       "           1.2144e-02,  2.6942e-03,  2.9316e-02, -8.8045e-02,  2.5873e-02,\n",
       "          -1.6045e-01, -8.4948e-02, -1.2183e-02,  4.5046e-02, -5.5165e-02,\n",
       "          -3.2471e-02,  1.3044e-01, -1.2209e-01,  8.3020e-02,  5.9915e-02,\n",
       "           1.9658e-02, -3.0819e-02,  1.6509e-01,  4.9545e-02,  6.7191e-02,\n",
       "          -1.8877e-02,  9.8550e-03,  1.5265e-01,  7.8301e-03, -7.5856e-02,\n",
       "           6.1397e-02, -3.3077e-03,  4.4769e-02,  1.9358e-02, -1.4352e-02,\n",
       "          -1.4745e-01, -2.5358e-02,  1.0845e-02,  8.6755e-02,  5.6569e-02,\n",
       "          -1.4698e-01, -4.3068e-02, -4.3180e-02,  3.4672e-03,  1.9544e-02,\n",
       "           9.6509e-02,  3.4723e-02,  2.4888e-02,  2.4547e-02,  3.4915e-02,\n",
       "          -3.9500e-02,  1.1247e-01, -7.6460e-02]]], device='cuda:0',\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c411a092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 56, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32d667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splade",
   "language": "python",
   "name": "splade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
