{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16616cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe403f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# generate top 1000 for retrieval trec:\n",
    "data_folder = \"../msmarco/\"\n",
    "\n",
    "corpus = {}  # dict in the format: passage_id -> passage. Stores all existing passages\n",
    "collection_filepath = os.path.join(data_folder, 'collection.tsv')\n",
    "\n",
    "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        pid, passage = line.strip().split(\"\\t\")\n",
    "        pid = int(pid)\n",
    "        corpus[pid] = passage\n",
    "\n",
    "queries = {}  # dict in the format: query_id -> query. Stores all training queries\n",
    "queries_filepath = os.path.join(data_folder, 'queries.train.tsv')\n",
    "    \n",
    "with open(queries_filepath, 'r', encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        qid, query = line.strip().split(\"\\t\")\n",
    "        qid = int(qid)\n",
    "        queries[qid] = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd9256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(\"../msmarco/yifan_bm25_top1000.psg.2019.trec.trec\") as f, \\\n",
    "    open(\"../msmarco/index_yifan_bm25_top1000.psg.2019.tsv\", \"w\") as fo:\n",
    "        for line in f:\n",
    "            qid, _, did, _, _, _ = line.split(\"\\t\")\n",
    "            fo.write(f\"{qid}\\t{did}\\t{queries[int(qid)]}\\t{corpus[int(did)]}\\n\")\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f0b5c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recip_rank 5 0.9465408805031447\n",
      "recip_rank 10 0.9465408805031447\n",
      "recip_rank 20 0.9465408805031447\n",
      "recip_rank 100 0.9465408805031447\n",
      "ndcg_cut_10 5 0.5015191336899024\n",
      "ndcg_cut_10 10 0.6654784780392424\n",
      "ndcg_cut_10 20 0.6654784780392424\n",
      "ndcg_cut_10 100 0.6654784780392424\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pytrec_eval\n",
    "from statistics import mean\n",
    "\n",
    "VALIDATION_METRIC = 'recip_rank'   #'recip_rank' #'ndcg_cut_10' \n",
    "\n",
    "qrel_file = \"../msmarco/2020qrels-pass.txt\" #\"../msmarco/qrels.dev.tsv\"\n",
    "\n",
    "qrels = defaultdict(dict)\n",
    "with open(qrel_file) as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            qid, _, did, rel = line.strip().split(\"\\t\")\n",
    "        except:\n",
    "            qid, _, did, rel = line.strip().split(\" \")\n",
    "        if int(rel) > 0:\n",
    "            qrels[qid][did] = int(rel)\n",
    "run = defaultdict(dict)\n",
    "with open(\"output_index_queries.2020.labeled.splade_max_156000.psg.tsv\") as f:\n",
    "    for line in f:\n",
    "        qid, did, score = line.split(\"\\t\")\n",
    "        run[qid][did] = float(score)\n",
    "        \n",
    "for VALIDATION_METRIC in ['recip_rank','ndcg_cut_10']:\n",
    "    for top_k in [5,10,20,100]:\n",
    "        top_run = defaultdict(dict)\n",
    "        for q in run:\n",
    "            docs = sorted(run[q].items(), key=lambda x: -x[1])\n",
    "            for item in docs[:top_k]:\n",
    "                top_run[q][item[0]] = item[1]\n",
    "        trec_eval = pytrec_eval.RelevanceEvaluator(qrels, {VALIDATION_METRIC})\n",
    "        eval_scores = trec_eval.evaluate(top_run)\n",
    "        print(VALIDATION_METRIC, top_k, mean([d[VALIDATION_METRIC] for d in eval_scores.values()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7a6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../msmarco/yifan_bm25_top1000.psg.train.trec.trec\") as f, \\\n",
    "    open(\"../msmarco/yifan_bm25_top100.psg.train.tsv\", \"w\") as fo:\n",
    "        for line in f:\n",
    "            qid, _, did, _, _, _ = line.split(\"\\t\")\n",
    "            fo.write(f\"{qid}\\t{did}\\t{queries[int(qid)]}\\t{corpus[int(did)]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ff29476",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "qrel = dict()\n",
    "with open(\"../msmarco/2020qrels-pass.txt\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, rel = line.split(\" \")\n",
    "        if int(rel) > 0:\n",
    "            qrel[qid] = did\n",
    "            \n",
    "qset = set()\n",
    "with open(\"../msmarco/msmarco-passagetest2020-top1000.tsv\") as f, \\\n",
    "    open(\"../msmarco/queries.2020.tsv\", \"w\") as fo:\n",
    "    for line in f:\n",
    "        qid, _, qtext, _ = line.split(\"\\t\")\n",
    "        if qid not in qset and qid in qrel:\n",
    "            fo.write(f\"{qid}\\t{qtext}\\n\")\n",
    "            qset.add(qid)\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3119fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO EVALUATE POSITIVE DOCUMENST NOT IN TOP 50 IN THE DATA\n",
    "queries = {}  # dict in the format: query_id -> query. Stores all training queries\n",
    "queries_filepath = os.path.join(data_folder, 'queries.train.tsv')\n",
    "    \n",
    "with open(queries_filepath, 'r', encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        qid, query = line.strip().split(\"\\t\")\n",
    "        qid = int(qid)\n",
    "        queries[qid] = query\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a217e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "qrel = dict()\n",
    "with open(\"../msmarco/qrels.train.tsv\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, rel = line.split(\"\\t\")\n",
    "        if int(rel) > 0:\n",
    "            qrel[qid] = did\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473a71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"../msmarco/yifan_bm25_top100.psg.train.trec.trec.rest\", 'w')\n",
    "from collections import defaultdict\n",
    "run_rerank = defaultdict(dict)\n",
    "\n",
    "with open(\"output_index_queries.train.splade_max_156000.psg.train.tsv\") as f:\n",
    "    for line in f:\n",
    "        qid, did, score = line.split(\"\\t\")\n",
    "        run_rerank[qid][did] = float(score)\n",
    "\n",
    "\n",
    "with open(\"../msmarco/yifan_bm25_top100.psg.train.trec.trec\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, _, _, _ = line.split(\"\\t\")\n",
    "        if did in run_rerank[qid]:\n",
    "            continue\n",
    "        fo.write(line)\n",
    "        \n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84f1a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run = defaultdict(dict)\n",
    "\n",
    "with open(\"../msmarco/queries.train.index_splade_num1_marginmse.psg.train.trec\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, _, _, _ = line.split(\"\\t\")\n",
    "        run[qid][did] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2257542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../msmarco/index_queries.train.index_splade_num1_marginmse.positive.psg.train.tsv\", \"w\") as fo:\n",
    "    for q in qrel:\n",
    "        if qrel[q] not in run[q]:\n",
    "            fo.write(f\"{q}\\t{qrel[q]}\\t{queries[int(q)]}\\t{corpus[int(qrel[q])]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59047588",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"output_index_train_colbert_scores_num2.tsv\", \"w\")\n",
    "for file in [\"output_index_queries.train.index_splade_num1_marginmse.300000+.tsv\",\\\n",
    "             \"output_index_queries.train.index_splade_num1_marginmse.220000-300000.tsv\",\\\n",
    "             \"output_index_queries.train.index_splade_num1_marginmse.0-220000.tsv\",\\\n",
    "             \"output_index_queries.train.index_splade_num1_marginmse.positive.tsv\"\n",
    "            ]:\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            fo.write(line)\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392dde86",
   "metadata": {},
   "source": [
    "# generate num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e301dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "qrel = dict()\n",
    "with open(\"../msmarco/qrels.train.tsv\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, rel = line.split(\"\\t\")\n",
    "        if int(rel) > 0:\n",
    "            qrel[qid] = did\n",
    "            \n",
    "run_retriever = defaultdict(dict)\n",
    "\n",
    "with open(\"../msmarco/queries.train.index_splade_num1_marginmse.psg.train.trec\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, rank, _, _ = line.split(\"\\t\")\n",
    "        run_retriever[qid][did] = float(rank)\n",
    "        \n",
    "run_rerank = defaultdict(dict)\n",
    "\n",
    "with open(\"output_index_train_colbert_scores_num2.tsv\") as f:\n",
    "    for line in f:\n",
    "        qid, did, score = line.split(\"\\t\")\n",
    "        run_rerank[qid][did] = float(score)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a039c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25\n",
    "from collections import defaultdict\n",
    "qrel = dict()\n",
    "with open(\"../msmarco/qrels.train.tsv\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, rel = line.split(\"\\t\")\n",
    "        if int(rel) > 0:\n",
    "            qrel[qid] = did\n",
    "            \n",
    "run_retriever = defaultdict(dict)\n",
    "\n",
    "with open(\"../msmarco/queries.train.splade_max_156000.psg.train.trec.trec\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, rank, _, _ = line.split(\"\\t\")\n",
    "        run_retriever[qid][did] = float(rank)\n",
    "        \n",
    "run_rerank = defaultdict(dict)\n",
    "\n",
    "with open(\"output_index_queries.train.splade_max_156000.psg.train.tsv\") as f:\n",
    "    for line in f:\n",
    "        qid, did, score = line.split(\"\\t\")\n",
    "        run_rerank[qid][did] = float(score)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4b6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "qrel = dict()\n",
    "with open(\"../msmarco/qrels.train.tsv\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, rel = line.split(\"\\t\")\n",
    "        if int(rel) > 0:\n",
    "            qrel[qid] = did\n",
    "            \n",
    "run_retriever = defaultdict(dict)\n",
    "\n",
    "with open(\"../msmarco/yifan_bm25_top1000.psg.train.trec.trec\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, rank, _, _ = line.split(\"\\t\")\n",
    "        run_retriever[qid][did] = float(rank)\n",
    "        \n",
    "run_rerank = defaultdict(dict)\n",
    "\n",
    "with open(\"../msmarco/bm25_colbert_ranking_train.tsv\") as f:\n",
    "    for line in f:\n",
    "        qid, did, score = line.split(\"\\t\")\n",
    "        run_rerank[qid][did] = -float(score)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd782dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gzip\n",
    "import pickle\n",
    "data_folder = \"../msmarco/\"\n",
    "ce_scores_file = os.path.join(data_folder, 'cross-encoder-ms-marco-MiniLM-L-6-v2-scores.pkl.gz')\n",
    "\n",
    "with gzip.open(ce_scores_file, 'rb') as fIn:\n",
    "    ce_scores = pickle.load(fIn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfbeecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 502939/502939 [34:18<00:00, 244.35it/s]\n"
     ]
    }
   ],
   "source": [
    "#queries里面的negative是按rerank的top排，x[0]是combine的rank，x[1]是did，x[2]是ce的rank\n",
    "import json,tqdm\n",
    "\n",
    "fo = open(\"training_queries_yifan_bm25_official_colbert.json\", \"w\")\n",
    "for q in tqdm.tqdm(run_rerank):\n",
    "    query = dict()\n",
    "\n",
    "    query['qid'] = int(q)\n",
    "    query['query'] = queries[int(q)]\n",
    "    did_list = sorted(run_rerank[q].items(), key = lambda x: -x[1])\n",
    "    combine = []\n",
    "    retrie = []\n",
    "    ce = []\n",
    "    for idx, pair in enumerate(did_list):\n",
    "        if pair[0] in run_retriever[q]:\n",
    "            combine.append(1/(idx + 61) + 1/(run_retriever[q][pair[0]] + 60))\n",
    "            retrie.append(1/(run_retriever[q][pair[0]] + 60))\n",
    "        else:\n",
    "            combine.append(1/(idx + 61) + 1/(1001 + 60))\n",
    "            retrie.append(1/(1001 + 60))\n",
    "        \n",
    "        if int(pair[0]) in ce_scores[int(q)]:\n",
    "            ce.append(ce_scores[int(q)][int(pair[0])])\n",
    "        else:\n",
    "            ce.append(0)\n",
    "            \n",
    "    combine_rank = [sorted(combine, key = lambda x: -x).index(x) for x in combine]\n",
    "    retrie_rank = [sorted(retrie, key = lambda x: -x).index(x) for x in retrie]\n",
    "    ce_rank = [sorted(ce, key = lambda x: -x).index(x) for x in ce]\n",
    "    \n",
    "    query['neg'] = [[x,int(y[0]),z] for x,y,z in zip(combine_rank, did_list, ce_rank)]\n",
    "    query[ \"splade_neg\"] = [[x,int(y[0]),z] for x,y,z in zip(retrie_rank, did_list, ce_rank)]\n",
    "    if qrel[q] not in [x[0] for x in did_list]:\n",
    "        query['pos'] = [[51, int(qrel[q]), 51]]\n",
    "        query['splade_pos'] = [[51, int(qrel[q]), 51]]\n",
    "    else:\n",
    "        pos_idx = ([x[0] for x in did_list]).index(qrel[q])\n",
    "        query['pos'] = [query['neg'][pos_idx]]\n",
    "        query['splade_pos'] = [query['splade_neg'][pos_idx]]\n",
    "    fo.write(f\"{q}\\t{json.dumps(query)}\\n\")\n",
    "    fo.flush()\n",
    "    \n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d7817c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "i =0 \n",
    "with open(\"training_queries_yifan_bm25_official_colbert.json\") as f, open(\"training_queries_yifan_bm25_official_colbert_ceclean.json\", 'w') as fo:\n",
    "    for line in f:\n",
    "        qid, query = line.split(\"\\t\")\n",
    "        query = json.loads(query)\n",
    "        idx = 0\n",
    "        while idx < len(query['neg']):\n",
    "            if query['neg'][idx][1] not in ce_scores[query['qid']]:\n",
    "                query['neg'].pop(idx)\n",
    "                idx -= 1\n",
    "            idx += 1\n",
    "            \n",
    "        idx = 0\n",
    "        while idx < len(query['splade_neg']):\n",
    "            if query['splade_neg'][idx][1] not in ce_scores[query['qid']]:\n",
    "                query['splade_neg'].pop(idx)\n",
    "                idx -= 1\n",
    "            idx += 1\n",
    "        fo.write(f\"{qid}\\t{json.dumps(query)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a0366d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# NEED TO EVALUATE POSITIVE DOCUMENST NOT IN TOP 50 IN THE DATA\n",
    "queries = {}  # dict in the format: query_id -> query. Stores all training queries\n",
    "data_folder = \"../msmarco\"\n",
    "queries_filepath = os.path.join(data_folder, 'queries.train.expand.splade_num1_marginmse.labeled.tsv')\n",
    "    \n",
    "with open(queries_filepath, 'r', encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        qid, query = line.strip().split(\"\\t\")\n",
    "        qid = int(qid)\n",
    "        queries[qid] = query\n",
    " \n",
    "\n",
    "\n",
    "with open(\"training_queries_num3_ceclean.json\") as f, open(\"training_queries_num3_ceclean_prf.json\", 'w') as fo:\n",
    "    for line in f:\n",
    "        qid, query = line.split(\"\\t\")\n",
    "        query = json.loads(query)\n",
    "        if query['qid'] in queries:\n",
    "            query['query'] = queries[query['qid']]\n",
    "            fo.write(f\"{qid}\\t{json.dumps(query)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5d7ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502938"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63395d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 502043/502043 [32:33<00:00, 256.98it/s]\n"
     ]
    }
   ],
   "source": [
    "#queries里面的negative是按rerank的top排，x[0]是combine的rank，x[1]是did，x[2]是ce的rank\n",
    "import json,tqdm\n",
    "\n",
    "fo = open(\"training_queries_yifan_bm25.json\", \"w\")\n",
    "for q in tqdm.tqdm(run_rerank):\n",
    "    query = dict()\n",
    "\n",
    "    query['qid'] = int(q)\n",
    "    query['query'] = queries[int(q)]\n",
    "    did_list = sorted(run_rerank[q].items(), key = lambda x: -x[1])\n",
    "    combine = []\n",
    "    retrie = []\n",
    "    ce = []\n",
    "    for idx, pair in enumerate(did_list):\n",
    "        if pair[0] in run_retriever[q]:\n",
    "            combine.append(1/(idx + 61) + 1/(run_retriever[q][pair[0]] + 60))\n",
    "            retrie.append(1/(run_retriever[q][pair[0]] + 60))\n",
    "        else:\n",
    "            combine.append(1/(idx + 61) + 1/(101 + 60))\n",
    "            retrie.append(1/(101 + 60))\n",
    "        \n",
    "        if int(pair[0]) in ce_scores[int(q)]:\n",
    "            ce.append(ce_scores[int(q)][int(pair[0])])\n",
    "        else:\n",
    "            ce.append(0)\n",
    "            \n",
    "    combine_rank = [sorted(combine, key = lambda x: -x).index(x) for x in combine]\n",
    "    retrie_rank = [sorted(retrie, key = lambda x: -x).index(x) for x in retrie]\n",
    "    ce_rank = [sorted(ce, key = lambda x: -x).index(x) for x in ce]\n",
    "    \n",
    "    query['neg'] = [[x,int(y[0]),z] for x,y,z in zip(combine_rank, did_list, ce_rank)]\n",
    "    query[ \"splade_neg\"] = [[x,int(y[0]),z] for x,y,z in zip(retrie_rank, did_list, ce_rank)]\n",
    "    if qrel[q] not in [x[0] for x in did_list]:\n",
    "        query['pos'] = [[51, int(qrel[q]), 51]]\n",
    "        query['splade_pos'] = [[51, int(qrel[q]), 51]]\n",
    "    else:\n",
    "        pos_idx = ([x[0] for x in did_list]).index(qrel[q])\n",
    "        query['pos'] = [query['neg'][pos_idx]]\n",
    "        query['splade_pos'] = [query['splade_neg'][pos_idx]]\n",
    "    fo.write(f\"{q}\\t{json.dumps(query)}\\n\")\n",
    "    fo.flush()\n",
    "    \n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3770b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "i =0 \n",
    "with open(\"training_queries_yifan_bm25.json\") as f, open(\"training_queries_yifan_bm25_ceclean.json\", 'w') as fo:\n",
    "    for line in f:\n",
    "        qid, query = line.split(\"\\t\")\n",
    "        query = json.loads(query)\n",
    "        idx = 0\n",
    "        while idx < len(query['neg']):\n",
    "            if query['neg'][idx][1] not in ce_scores[query['qid']]:\n",
    "                query['neg'].pop(idx)\n",
    "                idx -= 1\n",
    "            idx += 1\n",
    "            \n",
    "        idx = 0\n",
    "        while idx < len(query['splade_neg']):\n",
    "            if query['splade_neg'][idx][1] not in ce_scores[query['qid']]:\n",
    "                query['splade_neg'].pop(idx)\n",
    "                idx -= 1\n",
    "            idx += 1\n",
    "        fo.write(f\"{qid}\\t{json.dumps(query)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c0b03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"training_queries_num3_ceclean.json\") as f:\n",
    "    for line in f:\n",
    "        qid, query = line.split(\"\\t\")\n",
    "        query = json.loads(query)\n",
    "        pos_id = query['pos'].pop(0)   #Pop positive and add at end\n",
    "        if pos_id[1] not in corpus:\n",
    "            print(pos_id[1])\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29de37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "i =0 \n",
    "ce_score_margin = 3\n",
    "with open(\"training_queries_splade_max_156000.json\") as f, open(\"training_queries_splade_max_156000_ceclean.json\", 'w') as fo:\n",
    "    for line in f:\n",
    "        qid, query = line.split(\"\\t\")\n",
    "        query = json.loads(query)\n",
    "        pos_min_ce_score = ce_scores[query['qid']][query['pos'][0][1]]\n",
    "        ce_score_threshold = pos_min_ce_score - ce_score_margin\n",
    "        \n",
    "        idx = 0\n",
    "        while idx < len(query['neg']):\n",
    "            if query['neg'][idx][1] not in ce_scores[query['qid']]:\n",
    "                query['neg'].pop(idx)\n",
    "                idx -= 1\n",
    "            elif ce_scores[query['qid']][query['neg'][idx][1]] > ce_score_threshold:\n",
    "                query['neg'].pop(idx)\n",
    "                idx -= 1\n",
    "            idx += 1\n",
    "            \n",
    "        idx = 0\n",
    "        while idx < len(query['splade_neg']):\n",
    "            if query['splade_neg'][idx][1] not in ce_scores[query['qid']]:\n",
    "                query['splade_neg'].pop(idx)\n",
    "                idx -= 1\n",
    "            idx += 1\n",
    "            \n",
    "        if len(query['neg']) > 0:\n",
    "            fo.write(f\"{qid}\\t{json.dumps(query)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423f25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "shuffle_triples = set()\n",
    "with open(\"training_queries_yifan_bm25_ceclean.json\") as f:\n",
    "    for line in f:\n",
    "        qid, query = line.split(\"\\t\")\n",
    "        query = json.loads(query)\n",
    "        pos_id = query['pos'][0][1]\n",
    "        pos_idx = query['pos'][0][0]\n",
    "        \n",
    "        for neg in query['neg']:\n",
    "            neg_id = neg[1]\n",
    "            neg_idx = neg[0]\n",
    "        \n",
    "            shuffle_triples.add((qid, pos_id, neg_id, neg_idx - pos_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed797f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8187955"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../msmarco/\")\n",
    "for n in shuffle_triples:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda6aa6",
   "metadata": {},
   "source": [
    "# generate num2 for ance + splade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822fa974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25146900it [00:26, 948777.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import tqdm\n",
    "\n",
    "splade_run = defaultdict(dict)\n",
    "\n",
    "'''\n",
    "with open(\"../msmarco/queries.train.splade_max_156000.psg.train.trec.trec\") as f:\n",
    "    for line in tqdm.tqdm(f):\n",
    "        qid, _, did, rank, _, _ = line.strip().split(\"\\t\")\n",
    "        splade_run[qid][did] = int(rank)\n",
    "'''\n",
    "with open(\"../msmarco/queries.train.index_splade_num1_marginmse.psg.train.trec\") as f:\n",
    "    for line in tqdm.tqdm(f):\n",
    "        qid, _, did, rank, _, _ = line.strip().split(\"\\t\")\n",
    "        splade_run[qid][did] = int(rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1930d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502939000it [06:24, 1307394.12it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ance_run = defaultdict(dict)\n",
    "q = None\n",
    "\n",
    "with open(\"/home/ec2-user/efs/pyserini/runs/run.msmarco-passage.ance.bf.train.tsv\") as f:\n",
    "    for line in tqdm.tqdm(f):\n",
    "        qid, did, rank = line.strip().split(\"\\t\")\n",
    "        if int(rank) > 100:\n",
    "            continue\n",
    "        ance_run[qid][did] = int(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2cf7871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 502939/502939 [46:35<00:00, 179.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#queries里面的negative是按rerank的top排，x[0]是combine的rank，x[1]是did，x[2]是ce的rank\n",
    "import json,tqdm\n",
    "\n",
    "fo = open(\"training_queries_ance_splade_distill.json\", \"w\")\n",
    "for q in tqdm.tqdm(ance_run):\n",
    "    query = dict()\n",
    "\n",
    "    query['qid'] = int(q)\n",
    "    query['query'] = queries[int(q)]\n",
    "    did_list = list(ance_run[q].items())\n",
    "    \n",
    "    combine = []\n",
    "    retrie = []\n",
    "    ce = []\n",
    "    for idx, pair in enumerate(did_list):\n",
    "        if pair[0] in splade_run[q]:\n",
    "            combine.append(1/(pair[1] + 60) + 1/(splade_run[q][pair[0]] + 60))\n",
    "            retrie.append(1/(splade_run[q][pair[0]] + 60))\n",
    "        else:\n",
    "            combine.append(1/(pair[1] + 60) + 1/(101 + 60))\n",
    "            retrie.append(1/(101 + 60))\n",
    "        \n",
    "        if int(pair[0]) in ce_scores[int(q)]:\n",
    "            ce.append(ce_scores[int(q)][int(pair[0])])\n",
    "        else:\n",
    "            ce.append(0)\n",
    "            \n",
    "    for d in set(splade_run[q].keys()) - set(ance_run[q].keys()):\n",
    "        did_list.append([d, 0])\n",
    "        combine.append(1/(splade_run[q][d] + 60) + 1/(101 + 60))\n",
    "        retrie.append(1/(splade_run[q][d]))\n",
    "        if int(d) in ce_scores[int(q)]:\n",
    "            ce.append(ce_scores[int(q)][int(d)])\n",
    "        else:\n",
    "            ce.append(0)\n",
    "        \n",
    "            \n",
    "    combine_rank = [sorted(combine, key = lambda x: -x).index(x) for x in combine]\n",
    "    retrie_rank = [sorted(retrie, key = lambda x: -x).index(x) for x in retrie]\n",
    "    ce_rank = [sorted(ce, key = lambda x: -x).index(x) for x in ce]\n",
    "    \n",
    "    query['neg'] = [[x,int(y[0]),z] for x,y,z in zip(combine_rank, did_list, ce_rank)]\n",
    "    query[ \"splade_neg\"] = [[x,int(y[0]),z] for x,y,z in zip(retrie_rank, did_list, ce_rank)]\n",
    "    if qrel[q] not in [x[0] for x in did_list]:\n",
    "        query['pos'] = [[51, int(qrel[q]), 51]]\n",
    "        query['splade_pos'] = [[51, int(qrel[q]), 51]]\n",
    "    else:\n",
    "        pos_idx = ([x[0] for x in did_list]).index(qrel[q])\n",
    "        query['pos'] = [query['neg'][pos_idx]]\n",
    "        query['splade_pos'] = [query['splade_neg'][pos_idx]]\n",
    "    fo.write(f\"{q}\\t{json.dumps(query)}\\n\")\n",
    "    fo.flush()\n",
    "\n",
    "\n",
    "\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "badc7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "i =0 \n",
    "#ce_score_margin = 3\n",
    "with open(\"training_queries_ance_splade_distill.json\") as f, open(\"training_queries_ance_splade_distill_ceclean.json\", 'w') as fo:\n",
    "    for line in f:\n",
    "        qid, query = line.split(\"\\t\")\n",
    "        query = json.loads(query)\n",
    "        pos_min_ce_score = ce_scores[query['qid']][query['pos'][0][1]]\n",
    "        #ce_score_threshold = pos_min_ce_score - ce_score_margin\n",
    "        \n",
    "        idx = 0\n",
    "        while idx < len(query['neg']):\n",
    "            if query['neg'][idx][1] not in ce_scores[query['qid']]:\n",
    "                query['neg'].pop(idx)\n",
    "                idx -= 1\n",
    "            #elif ce_scores[query['qid']][query['neg'][idx][1]] > ce_score_threshold:\n",
    "            #    query['neg'].pop(idx)\n",
    "            #    idx -= 1\n",
    "            idx += 1\n",
    "            \n",
    "        idx = 0\n",
    "        while idx < len(query['splade_neg']):\n",
    "            if query['splade_neg'][idx][1] not in ce_scores[query['qid']]:\n",
    "                query['splade_neg'].pop(idx)\n",
    "                idx -= 1\n",
    "            idx += 1\n",
    "            \n",
    "        if len(query['neg']) > 0:\n",
    "            fo.write(f\"{qid}\\t{json.dumps(query)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "294a382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "run = defaultdict(list)\n",
    "with open(\"../msmarco/index_splade_num1_marginmse.psg.dev.trec.trec\") as f:\n",
    "    for line in f:\n",
    "        qid, _, did, rank, _, _ = line.strip().split(\"\\t\")\n",
    "        if int(rank) <= 100:\n",
    "            run[qid].append(did)\n",
    "            \n",
    "with open(\"../msmarco/index_splade_num1_marginmse.psg.dev.tsv\") as f, open(\"../msmarco/index_splade_num1_marginmse_top100.psg.dev.tsv\", \"w\") as fo:\n",
    "    for line in f:\n",
    "        qid, did, _, _ = line.strip().split(\"\\t\")\n",
    "        if did in run[qid]:\n",
    "            fo.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17340f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698000 ../msmarco/index_splade_num1_marginmse_top100.psg.dev.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../msmarco/index_splade_num1_marginmse_top100.psg.dev.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703621c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splade",
   "language": "python",
   "name": "splade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
